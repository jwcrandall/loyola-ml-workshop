{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Features \n",
    "## Introduction\n",
    "Given a dataset of $M$ variables and $N$ dataset points, a feature is one of the **independent** variables in a dataset and also called as a **predictor**. Generally the input to a machine learning program is a column of a tabular dataset where each row (of $N$ rows) is a dataset point in $M$ dimensional space.\n",
    "\n",
    "In our Jupyter notebooks we will use the matrix $X_{N \\times M}$ as the dataset symbol without the dependent variable (also called the label, category, class, predicted variable) and we will store the dependent variable in the vector $y_{N \\times 1}$.\n",
    "\n",
    "$X$ is a matrix. It's rows are data points and it's columns are the features. All classifiers in `scikit-learn` can understand this data format which is based on numpy 2-dimensional arrays. Thus for each input data point we have $x \\in \\mathbb{R}^{M}$, and we have $N$ data points to be used in our ML pipelines. We also have $y \\in \\mathbb{Z}$ in general as the category. As an example, if we have __$K$__ categories, then $y \\in\\{k: 0 \\leq k \\leq K, k \\in \\mathbb{Z}\\}$\n",
    "\n",
    "__Example:__ In the following $X$ matrix we have 3 features and 5 data points, i.e. $M=3$  and $N=5$. We also have 5 values for dependent variable $y$.\n",
    "\n",
    "$X=\\left[\\begin{array}{lll}x_{11} & x_{12} & x_{13} \\\\ x_{21} & x_{22} & x_{23} \\\\ x_{31} & x_{32} & x_{33} \\\\ x_{41} & x_{42} & x_{43} \\\\ x_{51} & x_{52} & x_{53}\\end{array}\\right], y=\\left[\\begin{array}{l}y_{1} \\\\ y_{2} \\\\ y_{3} \\\\ y_{4} \\\\ y_{5}\\end{array}\\right]$\n",
    "\n",
    "Such that in practice, $X=\\left[\\begin{array}{ccc}4.9 & 3 . & 1.4 \\\\ 4.7 & 3.2 & 1.3 \\\\ 4.6 & 3.1 & 1.5 \\\\ 5 . & 3.6 & 1.4 \\\\ 5.4 & 3.9 & 1.7\\end{array}\\right], y=\\left[\\begin{array}{l}1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 2\\end{array}\\right]$\n",
    "\n",
    "where the dependent variable $y$ has levels from the alphabet $\\Sigma=\\{0,1,2\\}$, i.e. there are 3 categories in the given dataset.\n",
    "\n",
    "The predicted variable or label is the __dependent__ variable and it is dependent on the __independent__ variables or features. This amount of dependence can be sometimes high and sometimes very low depending on the dataset or the nature of the problem (again, dataset expresses this). If there is no correlation (or fully independent), then the dataset may not be suitable for the problem at hand and/or we may have to remove that feature from the dataset.\n",
    "\n",
    "As an example, for numerical variables, the Pearson correlation coefficient of two variables $x$ (lower case x, a feature) and $y$ is defined as:\n",
    "\n",
    "$r_{x y}=\\frac{\\sum_{i=1}^{N}\\left(x_{i}-\\bar{x}\\right)\\left(y_{i}-\\bar{y}\\right)}{\\sqrt{\\sum_{i=1}^{N}\\left(x_{i}-\\bar{x}\\right)^{2}} \\sqrt{\\sum_{i=1}^{N}\\left(y_{i}-\\bar{y}\\right)^{2}}}$, where $\\bar{x}$ and $\\bar{y}$ are sample means.\n",
    "\n",
    "Ideally, we need a good correlation (close to 1 or -1) between the independent and dependent (predicted) variables so our ML model would actually work.\n",
    "\n",
    "__Question:__ Can correlation coefficient be used for determining important features for the machine learning model?\n",
    "\n",
    "## Data types\n",
    "* Numerical - Can be integer $\\mathbb{Z}$ or floating point $\\mathbb{R}$. Generally it is safe to convert all numerical variables to floating point variables.\n",
    "* Nominal - The variable values are drawn from a finite set of __levels__ or from an alphabet $\\Sigma$.\n",
    "* Binary - The variable values can be either `0` or `1` (or, `False` or `True`). Some algorithms work fast on this kind of values, especially constrained optimization related methods.\n",
    "* String - May not be used directly unless the ML program (preprocessing) knows how to deal with it\n",
    "* Date - May not be used directly unless the ML program (preprocessing) knows how to deal with it. It might be a good idea to convert (or map) dates to some integer numbers - for example, Excel handles dates in this manner.\n",
    "* More complicated features, e.g. a DNA sequence (sequence of {A,C,G,T} letters) - Other, simpler, features need to be extracted from the input sequence so that this higher-level feature can be used in an ML program.\n",
    "\n",
    "## Nominal to Numerical Conversion\n",
    "One possible way of converting nominal variables to numerical is one-hot encoding:\n",
    "\n",
    "1. During preprocessing count the number of levels in the set of possible levels a nominal variable $v_{nom}$ takes. Such as, $L$ different levels, $k=1, \\ldots, L$.\n",
    "2. Create $L$ binary variables for that nominal variable $v_{nom}$  where each row will have a binary zero for $L-1$ binary variables except for the $j^{th}$ level which corresponds to the level-j when $v_{nom}$ takes a value of level-j.\n",
    "\n",
    "Following above procedure, a nominal variable with a cardinality of $L$ results in $L$ many binary variable creation (and dropping the original nominal variable itself). In other words, each unique level of that nominal variable is mapped to a binary variable. Note that, for the sake of this representation, storage space is wasted.\n",
    "\n",
    "Also observe that the one-hot encoded variables are like unit vectors of linear algebra.\n",
    "\n",
    "Conversion of nominal variables to numerical is an important step for many numerical-only classifiers, such as neural networks, support vector machines, and linear regression.\n",
    "\n",
    "### Example One-hot Encoding\n",
    "The nominal variable $T$ take levels from the $\\Sigma=\\{$ low, medium, high $\\}$. Numerical conversion involves each unique level being mapped to one of the $T_i$ binary vectors.\n",
    "\n",
    "| __Nominal Variable $T$__  | $T_0$ | $T_1$ | $T_2$ |\n",
    "|---------------------------|-------|-------|-------|\n",
    "| low                       | 1     | 0     | 0     |\n",
    "| medium                    | 0     | 1     | 0     |         \n",
    "| low                       | 1     | 0     | 0     |\n",
    "| high                      | 0     | 0     | 1     |\n",
    "| high                      | 0     | 0     | 1     |\n",
    "| low                       | 1     | 0     | 0     |\n",
    "\n",
    "## Numerical to Nominal Conversion\n",
    "Generally, histograms, binning and bin boundaries are used to group numerical values into levels or one-hot encoded variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Dataset Sources\n",
    "The UCI KDD online repository has various datasets which can be used for analysis, machine learning and several application fields, such as GIS, cybersecurity, NLP, etc. The origin of some datasets go back to more than 20 years sourced from competitions, challenges, grants, etc. Researchers and students use these datasets and share their experiences using a common platform.  \n",
    "Source: UCI Knowledge Discovery in Databases Archive http://kdd.ics.uci.edu/\n",
    "\n",
    "**Kaggle** data repository has various datasets which are used for Kaggle competitions. The web site also has tools to examine the features on-site. This source is one of the largest.\n",
    "Go to the Kaggle dataset source: https://www.kaggle.com/datasets\n",
    "\n",
    "**KDnuggets** is another web page which encompasses almost everything (posts, news, datasets, tutorials, forums, webinars, software, etc.) that is relevant to machine learning and data analysis.\n",
    "Source: KDnuggets Datasets for Data Mining and https://www.kdnuggets.com/datasets/index.html\n",
    "\n",
    "The rest of the notebook will demonstrate three different datasets from these repositories.\n",
    "\n",
    "* UCI KDD archive  →  1990 US Census data\n",
    "* Kaggle  →  Graduate Admissions data\n",
    "* Kaggle  →  The Human Freedom Index data\n",
    "\n",
    "Download the data files from UCI KDD web site and Kaggle web site (by registering to Kaggle -using a disposable email address- if necessary).\n",
    "\n",
    "**Important Note:** About physical dataset file shared among teams. Comparing machine learning models, and measuring performances for model selection is heavily dependent on the input dataset. Thus, if a comparison between models and a comparison among different experiments or teams results are at hand, then the dataset shared among teams or different set of experiments must be exactly the same dataset. Moreover, to ensure the validity, the exact same file should be shared among multiple teams or between different models pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*WATCH THE LECTURE* for downloading files from online sources.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells we use the downloaded and previously cleaned data files:\n",
    "\n",
    "* `USCensus1990.data.csv`\n",
    "* `Admission_Predict.csv`\n",
    "* `hfi_cc_2018_cleaned.csv`\n",
    "\n",
    "Note that there are two dataset cleaning tasks before a machine learning model development can begin:\n",
    "\n",
    "* Cleaning the data so the framework understands the data right, i.e. formatting, removing confusing symbols, quotes, etc.\n",
    "* Cleaning (preprocessing) the data to improve the ML task, i.e. imputing values, removing outliers, removing incorrect dataset values, deriving variables, selecting variables, etc.\n",
    "\n",
    "Both cleaning steps are crucial in preparing the dataset for model development.\n",
    "\n",
    "__Quote:__ \"As data scientists, our job is to extract signal from noise.\" (ref: KDnuggets)\n",
    "\n",
    "---\n",
    "\n",
    "Let's see what our data files contain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T21:45:20.013455Z",
     "start_time": "2020-08-12T21:45:19.309981Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Locate and load the data file\n",
    "df = pd.read_csv('datasets/USCensus1990.data.csv')\n",
    "\n",
    "# Sanity check\n",
    "print(f'N rows={len(df)}, M columns={len(df.columns)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T21:45:20.027971Z",
     "start_time": "2020-08-12T21:45:20.015278Z"
    }
   },
   "outputs": [],
   "source": [
    "# Locate and load the data file\n",
    "df = pd.read_csv('datasets/Admission_Predict_Ver1.1.csv')\n",
    "\n",
    "# Sanity check\n",
    "print(f'N rows={len(df)}, M columns={len(df.columns)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T21:45:20.075104Z",
     "start_time": "2020-08-12T21:45:20.030300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Locate and load the data file\n",
    "df = pd.read_csv('../datasets/hfi_cc_2018.csv')\n",
    "\n",
    "# Sanity check\n",
    "print(f'N rows={len(df)}, M columns={len(df.columns)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Human Freedom Index Dataset¶\n",
    "Opening the `hfi_cc_2018` CSV data file in Weka is tricky as it needs two modifications as in below:\n",
    "\n",
    "* Using a text editor, change the value `\"d'Ivoire\"` to `\"dIvoire\"` by removing the single quote. The single quote is used by Weka to mark nominal variables.\n",
    "* Using a text editor add single quotes to the feature name __region__ to mark it as nominal. Weka wants to see single quotes in the variable name (in the header) to be able to load the type of the variables correctly.\n",
    "\n",
    "\n",
    "This particular example shows that data mining, machine learning frameworks such as Weka have their own standards that the model developer has to pay attention.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weka Framework\n",
    "\n",
    "Weka is a data analytics framework (open-source, Java based) with very strong ML and data mining abilities. To install:\n",
    "\n",
    "1. Download and install __64-bi__ Java JRE https://www.java.com/en/download/\n",
    "2. Download Weka Linux distro zip file from https://www.cs.waikato.ac.nz/ml/weka/downloading.html\n",
    "\n",
    "and extract the zip to `C:\\weka` on your computer's local disk. Use Windows command prompt:\n",
    "\n",
    "1. Check the version of Java: `java -version` so that make sure the `java` on the path is reflected to the one downloaded.\n",
    "2. On a command prompt, run `java -Xmx8g -jar c:\\weka\\weka.jar` (8GB heap space to be used for big data files - make sure your computer supports, or adjust this value)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*WATCH THE RELATED LECTURE* for opening, using Weka, preprocessing and running Random Forest classifier.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate Admissions Dataset\n",
    "Let's open the data file `Admission_Predict.csv` in Weka. Click on `Explorer` and open the CSV file with `Open File` button. We need a dependent variable to predict or do something with it. Let's pick `A9 - Chance of Admit` (`A_XX` is the attribute which starts from index 1). We need to convert this variable to a categorical variable.Let's open the data file `Admission_Predict.csv` in Weka. Click on `Explorer` and open the CSV file with `Open File` button. We need a dependent variable to predict or do something with it. Let's pick `A9 - Chance of Admit` (`A_XX` is the attribute which starts from index 1). We need to convert this variable to a categorical variable.\n",
    "\n",
    "1. In Filter, `AddExpression -E \"ifelse (A9 > 0.9, 1, 0)\" -N Admit` then press `Apply`\n",
    "2. In Filter, `NumericToNominal -R last`\n",
    "3. In Filter, `RenameNominalValues -R last -N \"0:No, 1:Yes\"`\n",
    "\n",
    "After preprocessing pick the RandomForest (RF) classifier from `Classifier-Trees-RandomForest`. Run it with 10-fold cross validation, with `Start` button. Observe the outcome\n",
    "\n",
    "**Question:** Why do you think RF model performance results 100%?\n",
    "\n",
    "Now remove the variable `\"Serial No.\"` (Why useless?) and remove `\"Chance of Admit\"` variable (`Remove` button down below). Remember we categorized it to the variable named `\"Admit\".`\n",
    "\n",
    "**Question:** Why do you think RF model performance is less than 100% now?\n",
    "\n",
    "---\n",
    "\n",
    "Student: Below cell can be safely ignored. This is the code to display markdown tables left oriented in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T21:45:20.079984Z",
     "start_time": "2020-08-12T21:45:20.076662Z"
    }
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "    table {margin-left: 0 !important;}\n",
    "</style>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
