{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T12:23:44.989064Z",
     "start_time": "2020-08-06T12:23:44.986800Z"
    }
   },
   "source": [
    "# Data Features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a dataset of  ğ‘€  variables and  ğ‘  dataset points, a feature is one of the **independent** variables in a dataset and also called as a **predictor**. Generally the input to a machine learning program is a column of a tabular dataset where each row (of  ğ‘  rows) is a dataset point in  ğ‘€  dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our Jupyter notebooks we will use the matrix  ğ‘‹ğ‘Ã—ğ‘€  as the dataset symbol without the dependent variable (also called the label, category, class, predicted variable) and we will store the dependent variable in the vector  ğ‘¦ğ‘Ã—1 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğ‘‹  is a matrix. It's rows are data points and it's columns are the features. All classifiers in scikit-learn can understand this data format which is based on numpy 2-dimensional arrays. Thus for each input data point we have  ğ‘¥âˆˆâ„ğ‘€ , and we have  ğ‘  data points to be used in our ML pipelines. We also have  ğ‘¦âˆˆâ„¤  in general as the category. As an example, if we have  ğ¾  categories, then  ğ‘¦âˆˆ{ğ‘˜:0â‰¤ğ‘˜â‰¤ğ¾,ğ‘˜âˆˆâ„¤}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** In the following  ğ‘‹  matrix we have 3 features and 5 data points, i.e.  ğ‘€=3  and  ğ‘=5 . We also have  5  values for dependent variable  ğ‘¦ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â© Guven\n",
    "Data Features \n",
    "Introduction\n",
    "Given a dataset of  ğ‘€  variables and  ğ‘  dataset points, a feature is one of the independent variables in a dataset and also called as a predictor. Generally the input to a machine learning program is a column of a tabular dataset where each row (of  ğ‘  rows) is a dataset point in  ğ‘€  dimensional space.\n",
    "\n",
    "In our Jupyter notebooks we will use the matrix  ğ‘‹ğ‘Ã—ğ‘€  as the dataset symbol without the dependent variable (also called the label, category, class, predicted variable) and we will store the dependent variable in the vector  ğ‘¦ğ‘Ã—1 .\n",
    "\n",
    "ğ‘‹  is a matrix. It's rows are data points and it's columns are the features. All classifiers in scikit-learn can understand this data format which is based on numpy 2-dimensional arrays. Thus for each input data point we have  ğ‘¥âˆˆâ„ğ‘€ , and we have  ğ‘  data points to be used in our ML pipelines. We also have  ğ‘¦âˆˆâ„¤  in general as the category. As an example, if we have  ğ¾  categories, then  ğ‘¦âˆˆ{ğ‘˜:0â‰¤ğ‘˜â‰¤ğ¾,ğ‘˜âˆˆâ„¤} \n",
    "Example: In the following  ğ‘‹  matrix we have 3 features and 5 data points, i.e.  ğ‘€=3  and  ğ‘=5 . We also have  5  values for dependent variable  ğ‘¦ .\n",
    "\n",
    "ğ‘‹=â¡â£â¢â¢â¢â¢â¢ğ‘¥11ğ‘¥21ğ‘¥31ğ‘¥41ğ‘¥51ğ‘¥12ğ‘¥22ğ‘¥32ğ‘¥42ğ‘¥52ğ‘¥13ğ‘¥23ğ‘¥33ğ‘¥43ğ‘¥53â¤â¦â¥â¥â¥â¥â¥ ,  ğ‘¦=â¡â£â¢â¢â¢â¢â¢ğ‘¦1ğ‘¦2ğ‘¦3ğ‘¦4ğ‘¦5â¤â¦â¥â¥â¥â¥â¥  â€ƒâ€ƒâ€ƒâ€ƒâ€ƒ Such that in practice,  ğ‘‹=â¡â£â¢â¢â¢â¢â¢4.94.74.65.5.43.3.23.13.63.91.41.31.51.41.7â¤â¦â¥â¥â¥â¥â¥ ,  ğ‘¦=â¡â£â¢â¢â¢â¢â¢10012â¤â¦â¥â¥â¥â¥â¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the dependent variable  ğ‘¦  has levels from the alphabet  Î£={0,1,2} , i.e. there are 3 categories in the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted variable or label is the **dependent** variable and it is dependent on the **independent** variables or features. This amount of dependence can be sometimes high and sometimes very low depending on the dataset or the nature of the problem (again, dataset expresses this). If there is no correlation (or fully independent), then the dataset may not be suitable for the problem at hand and/or we may have to remove that feature from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, for numerical variables, the Pearson correlation coefficient of two variables  ğ‘¥  (lower case x, a feature) and  ğ‘¦  is defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğ‘Ÿğ‘¥ğ‘¦=âˆ‘ğ‘ğ‘–=1(ğ‘¥ğ‘–âˆ’ğ‘¥Â¯)(ğ‘¦ğ‘–âˆ’ğ‘¦Â¯)âˆ‘ğ‘ğ‘–=1(ğ‘¥ğ‘–âˆ’ğ‘¥Â¯)2â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾âˆšâˆ‘ğ‘ğ‘–=1(ğ‘¦ğ‘–âˆ’ğ‘¦Â¯)2â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾âˆš , where  ğ‘¥Â¯  and  ğ‘¦Â¯  are sample means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we need a good correlation (close to 1 or -1) between the independent and dependent (predicted) variables so our ML model would actually work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Can correlation coefficient be used for determining important features for the machine learning model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Numerical - Can be integer  â„¤  or floating point  â„ . Generally it is safe to convert all numerical variables to floating point variables.\n",
    "* Nominal - The variable values are drawn from a finite set of levels or from an alphabet  Î£ .\n",
    "* Binary - The variable values can be either 0 or 1 (or, False or True). Some algorithms work fast on this kind of values, especially constrained optimization related methods.\n",
    "* String - May not be used directly unless the ML program (preprocessing) knows how to deal with it\n",
    "* Date - May not be used directly unless the ML program (preprocessing) knows how to deal with it. It might be a good idea to convert (or map) dates to some integer numbers - for example, Excel handles dates in this manner.\n",
    "* More complicated features, e.g. a DNA sequence (sequence of {A,C,G,T} letters) - Other, simpler, features need to be extracted from the input sequence so that this higher-level feature can be used in an ML program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nominal to Numerical Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One possible way of converting nominal variables to numerical is one-hot encoding:\n",
    "\n",
    "1. During preprocessing count the number of levels in the set of possible levels a nominal variable  ğ‘£ğ‘›ğ‘œğ‘š  takes. Such as,  ğ¿  different levels,  ğ‘˜=1,...,ğ¿ .\n",
    "2. Create  ğ¿  binary variables for that nominal variable  ğ‘£ğ‘›ğ‘œğ‘š  where each row will have a binary zero for  ğ¿âˆ’1  binary variables except for the jth level which corresponds to the level-j when  ğ‘£ğ‘›ğ‘œğ‘š  takes a value of level-j.\n",
    "\n",
    "Following above procedure, a nominal variable with a cardinality of  ğ¿  results in  ğ¿  many binary variable creation (and dropping the original nominal variable itself). In other words, each unique level of that nominal variable is mapped to a binary variable. Note that, for the sake of this representation, storage space is wasted.\n",
    "\n",
    "Also observe that the one-hot encoded variables are like unit vectors of linear algebra.\n",
    "\n",
    "Conversion of nominal variables to numerical is an important step for many numerical-only classifiers, such as neural networks, support vector machines, and linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example One-hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nominal variable  ğ‘‡  take levels from the  Î£={low,medium,high} . Numerical conversion involves each unique level being mapped to one of the  ğ‘‡ğ‘–  binary vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T13:09:10.888267Z",
     "start_time": "2020-08-06T13:09:10.884848Z"
    }
   },
   "source": [
    "Nominal Variable  ğ‘‡ \t ğ‘‡0 \t ğ‘‡1 \t ğ‘‡2 \n",
    "low\t1\t0\t0\n",
    "medium\t0\t1\t0\n",
    "low\t1\t0\t0\n",
    "high\t0\t0\t1\n",
    "high\t0\t0\t1\n",
    "low\t1\t0\t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical to Nominal Conversion\n",
    "Generally, histograms, binning and bin boundaries are used to group numerical values into levels or one-hot encoded variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Dataset Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI KDD online repository has various datasets which can be used for analysis, machine learning and several application fields, such as GIS, cybersecurity, NLP, etc. The origin of some datasets go back to more than 20 years sourced from competitions, challenges, grants, etc. Researchers and students use these datasets and share their experiences using a common platform.\n",
    "\n",
    "Source: UCI Knowledge Discovery in Databases Archive http://kdd.ics.uci.edu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kaggle** data repository has various datasets which are used for Kaggle competitions. The web site also has tools to examine the features on-site. This source is one of the largest.\n",
    "Go to the Kaggle dataset source: https://www.kaggle.com/datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KDnuggets** is another web page which encompasses almost everything (posts, news, datasets, tutorials, forums, webinars, software, etc.) that is relevant to machine learning and data analysis.\n",
    "Source: KDnuggets Datasets for Data Mining and https://www.kdnuggets.com/datasets/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the notebook will demonstrate three different datasets from these repositories.\n",
    "\n",
    "* UCI KDD archive  â†’  1990 US Census data\n",
    "* Kaggle  â†’  Graduate Admissions data\n",
    "* Kaggle  â†’  The Human Freedom Index data\n",
    "\n",
    "Download the data files from UCI KDD web site and Kaggle web site (by registering to Kaggle -using a disposable email address- if necessary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note:** About physical dataset file shared among teams. Comparing machine learning models, and measuring performances for model selection is heavily dependent on the input dataset. Thus, if a comparison between models and a comparison among different experiments or teams results are at hand, then the dataset shared among teams or different set of experiments must be exactly the same dataset. Moreover, to ensure the validity, the exact same file should be shared among multiple teams or between different models pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells we use the downloaded and previously cleaned data files:\n",
    "\n",
    "* USCensus1990.data.csv\n",
    "* Admission_Predict.csv\n",
    "* hfi_cc_2018_cleaned.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T13:12:51.711560Z",
     "start_time": "2020-08-06T13:12:51.707072Z"
    }
   },
   "source": [
    "Note that there are two dataset cleaning tasks before a machine learning model development can begin:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T13:14:20.492896Z",
     "start_time": "2020-08-06T13:14:20.487561Z"
    }
   },
   "source": [
    "* Cleaning the data so the framework understands the data right, i.e. formatting, removing confusing symbols, quotes, etc.\n",
    "* Cleaning (preprocessing) the data to improve the ML task, i.e. imputing values, removing outliers, removing incorrect dataset values, deriving variables, selecting variables, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both cleaning steps are crucial in preparing the dataset for model development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quote:** \"As data scientists, our job is to extract signal from noise.\" (ref: KDnuggets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T13:16:09.587166Z",
     "start_time": "2020-08-06T13:16:09.585253Z"
    }
   },
   "source": [
    "Let's see what our data files contain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T15:07:36.961672Z",
     "start_time": "2020-08-06T15:07:36.378096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N rows=30640, M columns=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josephcrandall/.pyenv/versions/3.7.3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Table 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>caseid</th>\n",
       "      <th>dAge</th>\n",
       "      <th>dAncstry1</th>\n",
       "      <th>dAncstry2</th>\n",
       "      <th>iAvail</th>\n",
       "      <th>iCitizen</th>\n",
       "      <th>iClass</th>\n",
       "      <th>dDepart</th>\n",
       "      <th>iDisabl1</th>\n",
       "      <th>iDisabl2</th>\n",
       "      <th>iEnglish</th>\n",
       "      <th>iFeb55</th>\n",
       "      <th>iFertil</th>\n",
       "      <th>dHispanic</th>\n",
       "      <th>dHour89</th>\n",
       "      <th>dHours</th>\n",
       "      <th>iImmigr</th>\n",
       "      <th>dIncome1</th>\n",
       "      <th>dIncome2</th>\n",
       "      <th>dIncome3</th>\n",
       "      <th>dIncome4</th>\n",
       "      <th>dIncome5</th>\n",
       "      <th>dIncome6</th>\n",
       "      <th>dIncome7</th>\n",
       "      <th>dIncome8</th>\n",
       "      <th>dIndustry</th>\n",
       "      <th>iKorean</th>\n",
       "      <th>iLang1</th>\n",
       "      <th>iLooking</th>\n",
       "      <th>iMarital</th>\n",
       "      <th>iMay75880</th>\n",
       "      <th>iMeans</th>\n",
       "      <th>iMilitary</th>\n",
       "      <th>iMobility</th>\n",
       "      <th>iMobillim</th>\n",
       "      <th>dOccup</th>\n",
       "      <th>iOthrserv</th>\n",
       "      <th>iPerscare</th>\n",
       "      <th>dPOB</th>\n",
       "      <th>dPoverty</th>\n",
       "      <th>dPwgt1</th>\n",
       "      <th>iRagechld</th>\n",
       "      <th>dRearning</th>\n",
       "      <th>iRelat1</th>\n",
       "      <th>iRelat2</th>\n",
       "      <th>iRemplpar</th>\n",
       "      <th>iRiders</th>\n",
       "      <th>iRlabor</th>\n",
       "      <th>iRownchld</th>\n",
       "      <th>dRpincome</th>\n",
       "      <th>iRPOB</th>\n",
       "      <th>iRrelchld</th>\n",
       "      <th>iRspouse</th>\n",
       "      <th>iRvetserv</th>\n",
       "      <th>iSchool</th>\n",
       "      <th>iSept80</th>\n",
       "      <th>iSex</th>\n",
       "      <th>iSubfam1</th>\n",
       "      <th>iSubfam2</th>\n",
       "      <th>iTmpabsnt</th>\n",
       "      <th>dTravtime</th>\n",
       "      <th>iVietnam</th>\n",
       "      <th>dWeek89</th>\n",
       "      <th>iWork89</th>\n",
       "      <th>iWorklwk</th>\n",
       "      <th>iWWII</th>\n",
       "      <th>iYearsch</th>\n",
       "      <th>iYearwrk</th>\n",
       "      <td>dYrsserv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>5</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>10</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <th>22</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>11</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <th>6</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>7</th>\n",
       "      <th>5</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>10</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>5</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>7</th>\n",
       "      <th>4</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <th>10</th>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>10</th>\n",
       "      <th>0</th>\n",
       "      <th>6</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>10</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>10</th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>10</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Table 1\n",
       "caseid dAge dAncstry1 dAncstry2 iAvail iCitizen iClass dDepart iDisabl1 iDisabl2 iEnglish iFeb55 iFertil dHispanic dHour89 dHours iImmigr dIncome1 dIncome2 dIncome3 dIncome4 dIncome5 dIncome6 dIncome7 dIncome8 dIndustry iKorean iLang1 iLooking iMarital iMay75880 iMeans iMilitary iMobility iMobillim dOccup iOthrserv iPerscare dPOB dPoverty dPwgt1 iRagechld dRearning iRelat1 iRelat2 iRemplpar iRiders iRlabor iRownchld dRpincome iRPOB iRrelchld iRspouse iRvetserv iSchool iSept80 iSex iSubfam1 iSubfam2 iTmpabsnt dTravtime iVietnam dWeek89 iWork89 iWorklwk iWWII iYearsch iYearwrk  dYrsserv\n",
       "10000  5    0         1         0      0        5      3       2        2        1        0      1       0         4       3      0       2        0        0        1        0        0        0        0        10        0       1      0        1        0         1      4         2         2         3      0         2         0    2        1      4         3         0       0       0         3       1       0         3         22    0         3        0         1       0       1    0        0        0         5         0        2       1       1        0     11       1                0\n",
       "10001  6    1         1         0      0        7      5       2        2        0        0      3       0         1       1      0       1        0        0        0        0        1        0        0        4         0       2      0        0        0         1      4         1         2         2      0         2         0    2        2      4         2         1       0       0         1       1       0         2         10    0         1        0         1       0       1    0        0        0         1         0        2       1       1        0     5        1                0\n",
       "10002  3    1         2         0      0        7      4       2        2        0        0      1       0         4       4      0       1        0        1        0        0        0        0        0        1         0       2      0        4        0         10     4         1         2         4      0         2         0    2        1      4         2         2       0       0         0       1       0         2         10    0         6        0         1       0       1    0        0        0         2         0        2       1       1        0     10       1                0\n",
       "10003  4    1         2         0      0        1      3       2        2        0        0      3       0         3       3      0       1        0        0        0        0        0        0        1        4         0       2      0        2        0         1      4         1         2         2      0         2         0    2        1      2         2         0       0       0         1       1       0         2         10    0         4        0         1       0       1    0        0        0         1         0        1       1       1        0     10       1                0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Locate and load the data file\n",
    "df = pd.read_csv('../datasets/USCensus1990.data.csv')\n",
    "\n",
    "# Sanity check\n",
    "print(f'N rows={len(df)}, M columns={len(df.columns)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T15:07:36.976067Z",
     "start_time": "2020-08-06T15:07:36.963483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N rows=500, M columns=9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Locate and load the data file\n",
    "df = pd.read_csv('../datasets/Admission_Predict_Ver1.1.csv')\n",
    "\n",
    "# Sanity check\n",
    "print(f'N rows={len(df)}, M columns={len(df.columns)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T15:07:37.024501Z",
     "start_time": "2020-08-06T15:07:36.978091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N rows=1458, M columns=123\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>ISO_code</th>\n",
       "      <th>countries</th>\n",
       "      <th>region</th>\n",
       "      <th>pf_rol_procedural</th>\n",
       "      <th>pf_rol_civil</th>\n",
       "      <th>pf_rol_criminal</th>\n",
       "      <th>pf_rol</th>\n",
       "      <th>pf_ss_homicide</th>\n",
       "      <th>pf_ss_disappearances_disap</th>\n",
       "      <th>...</th>\n",
       "      <th>ef_regulation_business_bribes</th>\n",
       "      <th>ef_regulation_business_licensing</th>\n",
       "      <th>ef_regulation_business_compliance</th>\n",
       "      <th>ef_regulation_business</th>\n",
       "      <th>ef_regulation</th>\n",
       "      <th>ef_score</th>\n",
       "      <th>ef_rank</th>\n",
       "      <th>hf_score</th>\n",
       "      <th>hf_rank</th>\n",
       "      <th>hf_quartile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Eastern Europe</td>\n",
       "      <td>6.661503</td>\n",
       "      <td>4.547244</td>\n",
       "      <td>4.666508</td>\n",
       "      <td>5.291752</td>\n",
       "      <td>8.920429</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.050196</td>\n",
       "      <td>7.324582</td>\n",
       "      <td>7.074366</td>\n",
       "      <td>6.705863</td>\n",
       "      <td>6.906901</td>\n",
       "      <td>7.54</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.568140</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>DZA</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Middle East &amp; North Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.819566</td>\n",
       "      <td>9.456254</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.765515</td>\n",
       "      <td>8.523503</td>\n",
       "      <td>7.029528</td>\n",
       "      <td>5.676956</td>\n",
       "      <td>5.268992</td>\n",
       "      <td>4.99</td>\n",
       "      <td>159.0</td>\n",
       "      <td>5.135886</td>\n",
       "      <td>155.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>AGO</td>\n",
       "      <td>Angola</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.451814</td>\n",
       "      <td>8.060260</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.945540</td>\n",
       "      <td>8.096776</td>\n",
       "      <td>6.782923</td>\n",
       "      <td>4.930271</td>\n",
       "      <td>5.518500</td>\n",
       "      <td>5.17</td>\n",
       "      <td>155.0</td>\n",
       "      <td>5.640662</td>\n",
       "      <td>142.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Latin America &amp; the Caribbean</td>\n",
       "      <td>7.098483</td>\n",
       "      <td>5.791960</td>\n",
       "      <td>4.343930</td>\n",
       "      <td>5.744791</td>\n",
       "      <td>7.622974</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.260044</td>\n",
       "      <td>5.253411</td>\n",
       "      <td>6.508295</td>\n",
       "      <td>5.535831</td>\n",
       "      <td>5.369019</td>\n",
       "      <td>4.84</td>\n",
       "      <td>160.0</td>\n",
       "      <td>6.469848</td>\n",
       "      <td>107.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>Caucasus &amp; Central Asia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.003205</td>\n",
       "      <td>8.808750</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.575152</td>\n",
       "      <td>9.319612</td>\n",
       "      <td>6.491481</td>\n",
       "      <td>6.797530</td>\n",
       "      <td>7.378069</td>\n",
       "      <td>7.57</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.241402</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year ISO_code  countries                         region  pf_rol_procedural  \\\n",
       "0  2016      ALB    Albania                 Eastern Europe           6.661503   \n",
       "1  2016      DZA    Algeria     Middle East & North Africa                NaN   \n",
       "2  2016      AGO     Angola             Sub-Saharan Africa                NaN   \n",
       "3  2016      ARG  Argentina  Latin America & the Caribbean           7.098483   \n",
       "4  2016      ARM    Armenia        Caucasus & Central Asia                NaN   \n",
       "\n",
       "   pf_rol_civil  pf_rol_criminal    pf_rol  pf_ss_homicide  \\\n",
       "0      4.547244         4.666508  5.291752        8.920429   \n",
       "1           NaN              NaN  3.819566        9.456254   \n",
       "2           NaN              NaN  3.451814        8.060260   \n",
       "3      5.791960         4.343930  5.744791        7.622974   \n",
       "4           NaN              NaN  5.003205        8.808750   \n",
       "\n",
       "   pf_ss_disappearances_disap  ...  ef_regulation_business_bribes  \\\n",
       "0                        10.0  ...                       4.050196   \n",
       "1                        10.0  ...                       3.765515   \n",
       "2                         5.0  ...                       1.945540   \n",
       "3                        10.0  ...                       3.260044   \n",
       "4                        10.0  ...                       4.575152   \n",
       "\n",
       "   ef_regulation_business_licensing  ef_regulation_business_compliance  \\\n",
       "0                          7.324582                           7.074366   \n",
       "1                          8.523503                           7.029528   \n",
       "2                          8.096776                           6.782923   \n",
       "3                          5.253411                           6.508295   \n",
       "4                          9.319612                           6.491481   \n",
       "\n",
       "   ef_regulation_business  ef_regulation  ef_score  ef_rank  hf_score  \\\n",
       "0                6.705863       6.906901      7.54     34.0  7.568140   \n",
       "1                5.676956       5.268992      4.99    159.0  5.135886   \n",
       "2                4.930271       5.518500      5.17    155.0  5.640662   \n",
       "3                5.535831       5.369019      4.84    160.0  6.469848   \n",
       "4                6.797530       7.378069      7.57     29.0  7.241402   \n",
       "\n",
       "   hf_rank  hf_quartile  \n",
       "0     48.0          2.0  \n",
       "1    155.0          4.0  \n",
       "2    142.0          4.0  \n",
       "3    107.0          3.0  \n",
       "4     57.0          2.0  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Locate and load the data file\n",
    "df = pd.read_csv('../datasets/hfi_cc_2018.csv')\n",
    "\n",
    "# Sanity check\n",
    "print(f'N rows={len(df)}, M columns={len(df.columns)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Human Freedom Index DatasetÂ¶\n",
    "Opening the hfi_cc_2018 CSV data file in Weka is tricky as it needs two modifications as in below:\n",
    "\n",
    "* Using a text editor, change the value \"d'Ivoire\" to \"dIvoire\" by removing the single quote. The single quote is used by Weka to mark nominal variables.\n",
    "* Using a text editor add single quotes to the feature name region to mark it as nominal. Weka wants to see single quotes in the variable name (in the header) to be able to load the type of the variables correctly.\n",
    "\n",
    "\n",
    "This particular example shows that data mining, machine learning frameworks such as Weka have their own standards that the model developer has to pay attention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weka Framework\n",
    "\n",
    "Weka is a data analytics framework (open-source, Java based) with very strong ML and data mining abilities. To install:\n",
    "\n",
    "1. Download and install 64-bit Java JRE https://www.java.com/en/download/\n",
    "2. Download Weka Linux distro zip file from https://www.cs.waikato.ac.nz/ml/weka/downloading.html\n",
    "\n",
    "and extract the zip to C:\\weka on your computer's local disk. Use Windows command prompt:\n",
    "\n",
    "1. Check the version of Java: java -version so that make sure the java on the path is reflected to the one downloaded.\n",
    "2. On a command prompt, run java -Xmx8g -jar c:\\weka\\weka.jar (8GB heap space to be used for big data files - make sure your computer supports, or adjust this value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WATCH THE RELATED LECTURE for opening, using Weka, preprocessing and running Random Forest classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate Admissions Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open the data file Admission_Predict.csv in Weka. Click on Explorer and open the CSV file with Open File button. We need a dependent variable to predict or do something with it. Let's pick A9 - Chance of Admit (A_XX is the attribute which starts from index 1). We need to convert this variable to a categorical variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T13:21:01.031056Z",
     "start_time": "2020-08-06T13:21:01.026868Z"
    }
   },
   "source": [
    "1. In Filter, AddExpression -E \"ifelse (A9 > 0.9, 1, 0)\" -N Admit then press Apply\n",
    "2. In Filter, NumericToNominal -R last\n",
    "3. In Filter, RenameNominalValues -R last -N \"0:No, 1:Yes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing pick the RandomForest (RF) classifier from Classifier-Trees-RandomForest. Run it with 10-fold cross validation, with Start button. Observe the outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Why do you think RF model performance results 100%?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now remove the variable \"Serial No.\" (Why useless?) and remove \"Chance of Admit\" variable (Remove button down below). Remember we categorized it to the variable named \"Admit\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T13:21:58.069956Z",
     "start_time": "2020-08-06T13:21:58.066732Z"
    }
   },
   "source": [
    "**Question:** Why do you think RF model performance is less than 100% now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student: Below cell can be safely ignored. This is the code to display markdown tables left oriented in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T15:07:37.029811Z",
     "start_time": "2020-08-06T15:07:37.026332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table {margin-left: 0 !important;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "    table {margin-left: 0 !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
